{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cardell/.local/lib/python3.10/site-packages/torch/jit/_trace.py:1093: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%63 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::normal(%55, %61, %62) # /home/cardell/.local/lib/python3.10/site-packages/torch/distributions/normal.py:70:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  _check_trace(\n",
      "/home/cardell/.local/lib/python3.10/site-packages/torch/jit/_trace.py:1093: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 256 / 256 (100.0%)\n",
      "Greatest absolute difference: 4.473320364952087 at index (0, 86) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 285.80344111196376 at index (0, 252) (up to 1e-05 allowed)\n",
      "  _check_trace(\n",
      "/home/cardell/.local/lib/python3.10/site-packages/torch/jit/_trace.py:160: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if a.grad is not None:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'flip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m skip_iteration \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m         flip \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mflip\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flip' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using A GAN created by Aladdin Persson, this is an attempt to create a VAE-GAN, where the VAE acts as the generator\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import vae as vae\n",
    "import reporter as rp\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),  # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "# Hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 1e-4\n",
    "z_dim = 256\n",
    "image_dim = 28 * 28 * 1  # 784\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "negative_slope = 0.01\n",
    "skip_iteration = 5\n",
    "\n",
    "\n",
    "# autoencoder = VAE(z_dim, 512).to(device)\n",
    "encoder_layers = nn.Sequential()\n",
    "encoder_layers.add_module('fc1', nn.Linear(image_dim, 512))\n",
    "encoder_layers.add_module('relu1', nn.LeakyReLU(negative_slope))\n",
    "encoder_layers.add_module('fc2', nn.Linear(512, 256))\n",
    "encoder_layers.add_module('relu2', nn.LeakyReLU(negative_slope))\n",
    "encoder_layers.add_module('fc3', nn.Linear(256, z_dim))\n",
    "encoder_layers.add_module('relu3', nn.LeakyReLU(negative_slope))\n",
    "\n",
    "encoder = vae.Encoder(encoder_layers)\n",
    "\n",
    "\n",
    "generator_layers = nn.Sequential()\n",
    "generator_layers.add_module('fc1', nn.Linear(z_dim, 256))\n",
    "generator_layers.add_module('relu1', nn.LeakyReLU(negative_slope))\n",
    "generator_layers.add_module('fc2', nn.Linear(256, 512))\n",
    "generator_layers.add_module('relu2', nn.LeakyReLU(negative_slope))\n",
    "generator_layers.add_module('fc3', nn.Linear(512, image_dim))\n",
    "generator_layers.add_module('relu3', nn.LeakyReLU(negative_slope))\n",
    "\n",
    "generator = vae.Decoder(generator_layers)\n",
    "\n",
    "discriminator = Discriminator(image_dim)\n",
    "\n",
    "\n",
    "dataset_mnist = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "data_loader_mnist = torch.utils.data.DataLoader(dataset_mnist, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "\n",
    "random_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "\n",
    "num_mini_batches = len(data_loader_mnist)\n",
    "epoch_mse_loss = 1.0\n",
    "epoch_kl_loss = 1.0\n",
    "epoch_discriminator_loss_real = 1.0\n",
    "epoch_discriminator_loss_fake = 1.0\n",
    "epoch_discriminator_loss = 1.0\n",
    "epoch_generator_loss = 1.0\n",
    "\n",
    "reporter = rp.Reporter('./logs/vae_gan', './logs/snapshots')\n",
    "\n",
    "images, labels = next(iter(data_loader_mnist))\n",
    "print(images.shape)\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "reporter.writer.add_graph(encoder, images[0])\n",
    "input = encoder(images[0])\n",
    "reporter.writer.add_graph(generator, input)\n",
    "reporter.writer.add_graph(discriminator, images[0])\n",
    "\n",
    "flip = True\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % skip_iteration == 0:\n",
    "        flip = not flip\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "    if(epoch > 0):\n",
    "        reporter.writer.add_scalar('MSE Loss', epoch_mse_loss, epoch)\n",
    "        reporter.writer.add_scalar('Discriminator Loss', epoch_discriminator_loss, epoch)\n",
    "        reporter.writer.add_scalar('Discriminator Loss Real', epoch_discriminator_loss_real, epoch)\n",
    "        reporter.writer.add_scalar('Discriminator Loss Fake', epoch_discriminator_loss_fake, epoch)\n",
    "        reporter.writer.add_scalar('Generator Loss', epoch_generator_loss, epoch)\n",
    "\n",
    "\n",
    "    print(f\"Epoch MSE Loss: {epoch_mse_loss}\")\n",
    "    epoch_mse_loss = 0\n",
    "    epoch_kl_loss = 0\n",
    "    epoch_discriminator_loss = 0\n",
    "    epoch_discriminator_loss_real = 0\n",
    "    epoch_discriminator_loss_fake = 0\n",
    "    epoch_generator_loss = 0\n",
    "\n",
    "    for i, (data, label) in enumerate (data_loader_mnist):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        batch_size = data.shape[0]\n",
    "\n",
    "        if flip:\n",
    "            # Train discriminator with real data\n",
    "            discriminator.zero_grad()\n",
    "            real_image = data.view(batch_size, -1)\n",
    "            #Expect real image to be classified as 1\n",
    "            real_iamge_label = torch.ones(batch_size, 1).to(device)\n",
    "            output_real = discriminator(real_image)\n",
    "\n",
    "            real_data_error = nn.BCELoss()(output_real, real_iamge_label)\n",
    "            epoch_discriminator_loss_real += real_data_error\n",
    "            real_data_error.backward(retain_graph=True)\n",
    "\n",
    "            # Train discriminator with fake data\n",
    "            z = encoder(real_image)\n",
    "\n",
    "            fake_image = generator(z)\n",
    "            #Expect fake image to be classified as 0\n",
    "            fake_image_label = torch.zeros(batch_size, 1).to(device)\n",
    "            output_fake = discriminator(fake_image)\n",
    "\n",
    "            fake_data_error = nn.BCELoss()(output_fake, fake_image_label)\n",
    "            epoch_discriminator_loss_fake += fake_data_error\n",
    "            fake_data_error.backward(retain_graph=True)\n",
    "\n",
    "            discriminator_error = real_data_error + fake_data_error\n",
    "            epoch_discriminator_loss += discriminator_error\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "        # Train VAE on MSE and KL divergence\n",
    "        generator.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "\n",
    "        z2 = encoder(real_image)\n",
    "        x_hat = generator(z2)\n",
    "\n",
    "        shaped_real_image = real_image.view(batch_size, 1, 28, 28)\n",
    "        MSE = F.mse_loss(x_hat, shaped_real_image, reduction='mean')\n",
    "        epoch_mse_loss += MSE\n",
    "        vae_loss = MSE + (0.1) * encoder.kl\n",
    "        vae_loss.backward(retain_graph=True)\n",
    "        generator_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        if not flip:\n",
    "            # Train generator/decoder on discriminator output\n",
    "            x_hat2 = generator(encoder(real_image))\n",
    "            generator.zero_grad() \n",
    "            discriminator_guess = discriminator(x_hat2)\n",
    "            generator_error = nn.BCELoss()(discriminator_guess, real_iamge_label)\n",
    "            epoch_generator_loss += generator_error\n",
    "            generator_error.backward()\n",
    "            encoder.zero_grad()\n",
    "            generator_optimizer.step()\n",
    "\n",
    "    epoch_mse_loss /= num_mini_batches\n",
    "    epoch_discriminator_loss /= num_mini_batches\n",
    "    epoch_discriminator_loss_real /= num_mini_batches\n",
    "    epoch_discriminator_loss_fake /= num_mini_batches\n",
    "    epoch_generator_loss /= num_mini_batches\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
